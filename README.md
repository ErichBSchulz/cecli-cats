# Cecli Atomic Tests

Its very hard to improve what you cannot measure.

Benchmarking enables us to chose the best model for our needs, and configure it to get the best out of it.

As models evolve, so must our tests and our metrics.

Cecli Atomic Tests (Cats) aim to enable us to tune hyper-parameters and cecli settings.

The proposed changes enable approaching a new set of more nuanced questions:

* "Which prompt is best?"
* "How do we get the best performance from a specific model (x model)?"
* "Which tests are best at discriminating certain optimisations?"

## Source Attribution

This is a fork of the [Aider polyglot benchmark](), based on a subset of repository contains a curated collection of programming exercises extracted from Exercism's language tracks. These exercises are used for benchmarking and testing purposes.

For more information see:

- [The aider blog](https://aider.chat/2024/12/21/polyglot.html)
- [The benchmark harness README](https://github.com/Aider-AI/aider/tree/main/benchmark)

All exercises in this repository are sourced from the following Exercism language tracks:

[C++](https://github.com/exercism/cpp), [Go](https://github.com/exercism/go), [Java](https://github.com/exercism/java), [JavaScript](https://github.com/exercism/javascript), [Python](https://github.com/exercism/python), [Rust](https://github.com/exercism/rust)

All exercise content is copyright Â© [Exercism](https://exercism.org). These exercises are used in accordance with Exercism's open source licenses.

Please visit [Exercism](https://exercism.org) or the
repos above to see licensing of these coding
exercises.
